#!/bin/bash
# migrate-config-v2.sh - Migrate Sekha v1.x configuration to v2.0
#
# This script helps migrate from v1.x environment variable configuration
# to the new v2.0 YAML-based multi-provider configuration.
#
# Usage:
#   ./scripts/migrate-config-v2.sh [--dry-run] [--output config.yaml]

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0;m' # No Color

# Configuration
OUTPUT_FILE="config.yaml"
DRY_RUN=false
BACKUP_DIR=".config-backups"

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --output)
            OUTPUT_FILE="$2"
            shift 2
            ;;
        --help|-h)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --dry-run         Show what would be generated without writing"
            echo "  --output FILE     Output file path (default: config.yaml)"
            echo "  --help, -h        Show this help message"
            echo ""
            echo "Examples:"
            echo "  $0 --dry-run                    # Preview migration"
            echo "  $0 --output my-config.yaml      # Write to custom file"
            exit 0
            ;;
        *)
            echo -e "${RED}Unknown option: $1${NC}"
            exit 1
            ;;
    esac
done

echo -e "${BLUE}╔════════════════════════════════════════════════════════╗${NC}"
echo -e "${BLUE}║  Sekha Configuration Migration: v1.x → v2.0            ║${NC}"
echo -e "${BLUE}╚════════════════════════════════════════════════════════╝${NC}"
echo ""

# Detect current configuration
echo -e "${YELLOW}[1/5] Detecting current configuration...${NC}"

if [ -f ".env" ]; then
    echo -e "${GREEN}✓${NC} Found .env file"
    source .env 2>/dev/null || true
fi

# Check for v1.x style env vars
has_v1_config=false
if [ ! -z "$OLLAMA_URL" ] || [ ! -z "$LLM_URL" ]; then
    has_v1_config=true
    echo -e "${GREEN}✓${NC} Detected v1.x configuration"
fi

if [ -f "$OUTPUT_FILE" ]; then
    echo -e "${YELLOW}⚠${NC}  Warning: $OUTPUT_FILE already exists"
    if [ "$DRY_RUN" = false ]; then
        read -p "Overwrite? [y/N] " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            echo -e "${RED}✗${NC} Migration cancelled"
            exit 1
        fi
    fi
fi

# Extract configuration values
echo -e "${YELLOW}[2/5] Extracting configuration values...${NC}"

# LLM configuration
OLLAMA_BASE_URL="${OLLAMA_URL:-${LLM_URL:-http://localhost:11434}}"
EMBEDDING_MODEL="${EMBEDDING_MODEL:-nomic-embed-text}"
CHAT_MODEL="${CHAT_MODEL:-${SUMMARIZATION_MODEL:-llama3.1:8b}}"
OPENAI_API_KEY="${OPENAI_API_KEY:-}"
ANTHROPIC_API_KEY="${ANTHROPIC_API_KEY:-}"
OPENROUTER_API_KEY="${OPENROUTER_API_KEY:-}"

echo -e "  Ollama URL: ${OLLAMA_BASE_URL}"
echo -e "  Embedding Model: ${EMBEDDING_MODEL}"
echo -e "  Chat Model: ${CHAT_MODEL}"
[ ! -z "$OPENAI_API_KEY" ] && echo -e "${GREEN}  ✓${NC} OpenAI API key found"
[ ! -z "$ANTHROPIC_API_KEY" ] && echo -e "${GREEN}  ✓${NC} Anthropic API key found"
[ ! -z "$OPENROUTER_API_KEY" ] && echo -e "${GREEN}  ✓${NC} OpenRouter API key found"

# Generate configuration
echo -e "${YELLOW}[3/5] Generating v2.0 configuration...${NC}"

# Determine embedding dimension
EMBEDDING_DIM=768
case "$EMBEDDING_MODEL" in
    nomic-embed-text) EMBEDDING_DIM=768 ;;
    mxbai-embed-large) EMBEDDING_DIM=1024 ;;
    text-embedding-3-small) EMBEDDING_DIM=1536 ;;
    text-embedding-3-large) EMBEDDING_DIM=3072 ;;
    text-embedding-ada-002) EMBEDDING_DIM=1536 ;;
esac

# Build YAML config
CONFIG=$(cat <<EOF
# Sekha v2.0 Configuration
# Generated by migration script from v1.x settings
# Date: $(date +"%Y-%m-%d %H:%M:%S")

config_version: "2.0"

llm_providers:
  # Local Ollama - Priority 1 (free, fast)
  - id: "ollama_local"
    type: "ollama"
    base_url: "${OLLAMA_BASE_URL}"
    api_key: null
    priority: 1
    models:
      - model_id: "${EMBEDDING_MODEL}"
        task: "embedding"
        context_window: 512
        dimension: ${EMBEDDING_DIM}
      - model_id: "${CHAT_MODEL}"
        task: "chat_small"
        context_window: 8192
      - model_id: "${CHAT_MODEL}"
        task: "chat_smart"
        context_window: 8192
EOF
)

# Add OpenAI provider if API key exists
if [ ! -z "$OPENAI_API_KEY" ]; then
    CONFIG+=$(cat <<EOF

  # OpenAI - Priority 2 (high quality, paid)
  - id: "openai_cloud"
    type: "openai"
    base_url: "https://api.openai.com/v1"
    api_key: "\${OPENAI_API_KEY}"
    priority: 2
    models:
      - model_id: "gpt-4o"
        task: "chat_smart"
        context_window: 128000
        supports_vision: true
      - model_id: "gpt-4o-mini"
        task: "chat_small"
        context_window: 128000
      - model_id: "text-embedding-3-large"
        task: "embedding"
        context_window: 8191
        dimension: 3072
EOF
    )
fi

# Add Anthropic provider if API key exists
if [ ! -z "$ANTHROPIC_API_KEY" ]; then
    CONFIG+=$(cat <<EOF

  # Anthropic - Priority 3 (Claude models)
  - id: "anthropic_direct"
    type: "anthropic"
    base_url: "https://api.anthropic.com/v1"
    api_key: "\${ANTHROPIC_API_KEY}"
    priority: 3
    models:
      - model_id: "claude-3-opus-20240229"
        task: "chat_smart"
        context_window: 200000
      - model_id: "claude-3-sonnet-20240229"
        task: "chat_small"
        context_window: 200000
EOF
    )
fi

# Add OpenRouter provider if API key exists
if [ ! -z "$OPENROUTER_API_KEY" ]; then
    CONFIG+=$(cat <<EOF

  # OpenRouter - Priority 4 (access to many models)
  - id: "openrouter"
    type: "openrouter"
    base_url: "https://openrouter.ai/api/v1"
    api_key: "\${OPENROUTER_API_KEY}"
    priority: 4
    models:
      - model_id: "deepseek/deepseek-v3"
        task: "chat_smart"
        context_window: 64000
      - model_id: "moonshot/kimi-2.5"
        task: "chat_smart"
        context_window: 256000
EOF
    )
fi

# Add default models and routing config
CONFIG+=$(cat <<EOF

default_models:
  embedding: "${EMBEDDING_MODEL}"
  chat_fast: "${CHAT_MODEL}"
  chat_smart: "${CHAT_MODEL}"
EOF
)

if [ ! -z "$OPENAI_API_KEY" ]; then
    CONFIG+=$(echo -e "\n  chat_vision: \"gpt-4o\"")
fi

CONFIG+=$(cat <<EOF

routing:
  auto_fallback: true
  require_vision_for_images: true
  max_cost_per_request: null  # No cost limit (set to float for budget)
  circuit_breaker:
    failure_threshold: 3
    timeout_secs: 60
    success_threshold: 2
EOF
)

echo -e "${GREEN}✓${NC} Configuration generated"

# Validate configuration (basic check)
echo -e "${YELLOW}[4/5] Validating configuration...${NC}"

if echo "$CONFIG" | grep -q "config_version: \"2.0\""; then
    echo -e "${GREEN}✓${NC} Version field present"
else
    echo -e "${RED}✗${NC} Missing version field"
    exit 1
fi

if echo "$CONFIG" | grep -q "llm_providers:"; then
    echo -e "${GREEN}✓${NC} Providers section present"
else
    echo -e "${RED}✗${NC} Missing providers section"
    exit 1
fi

if echo "$CONFIG" | grep -q "default_models:"; then
    echo -e "${GREEN}✓${NC} Default models section present"
else
    echo -e "${RED}✗${NC} Missing default models section"
    exit 1
fi

echo -e "${GREEN}✓${NC} Configuration valid"

# Write configuration
echo -e "${YELLOW}[5/5] Writing configuration...${NC}"

if [ "$DRY_RUN" = true ]; then
    echo -e "${BLUE}[DRY RUN] Would write to: $OUTPUT_FILE${NC}"
    echo ""
    echo -e "${BLUE}────── Configuration Preview ──────${NC}"
    echo "$CONFIG"
    echo -e "${BLUE}───────────────────────────────────${NC}"
else
    # Create backup
    if [ -f "$OUTPUT_FILE" ]; then
        mkdir -p "$BACKUP_DIR"
        backup_file="$BACKUP_DIR/$(basename $OUTPUT_FILE).$(date +%Y%m%d_%H%M%S).bak"
        cp "$OUTPUT_FILE" "$backup_file"
        echo -e "${GREEN}✓${NC} Backed up existing config to: $backup_file"
    fi
    
    if [ -f ".env" ] && [ ! -f "$BACKUP_DIR/.env.bak" ]; then
        mkdir -p "$BACKUP_DIR"
        cp ".env" "$BACKUP_DIR/.env.$(date +%Y%m%d_%H%M%S).bak"
        echo -e "${GREEN}✓${NC} Backed up .env file"
    fi
    
    # Write config
    echo "$CONFIG" > "$OUTPUT_FILE"
    echo -e "${GREEN}✓${NC} Wrote configuration to: $OUTPUT_FILE"
fi

# Summary
echo ""
echo -e "${GREEN}╔════════════════════════════════════════════════════════╗${NC}"
echo -e "${GREEN}║  Migration Complete!                                   ║${NC}"
echo -e "${GREEN}╚════════════════════════════════════════════════════════╝${NC}"
echo ""
echo -e "${YELLOW}Next steps:${NC}"
echo -e "  1. Review the generated $OUTPUT_FILE"
echo -e "  2. Update your .env file:"
echo -e "     ${BLUE}export LLM_BRIDGE_URL='http://localhost:5001'${NC}"
echo -e "  3. Remove deprecated variables:"
echo -e "     ${BLUE}unset OLLAMA_URL LLM_URL LLM_PROVIDER${NC}"
echo -e "  4. Restart services:"
echo -e "     ${BLUE}docker-compose down && docker-compose up -d${NC}"
echo -e "  5. Verify routing:"
echo -e "     ${BLUE}curl http://localhost:5001/api/v1/models${NC}"
echo ""
echo -e "${YELLOW}Documentation:${NC}"
echo -e "  • docs/migration-guide-v2.md - Complete migration guide"
echo -e "  • docs/configuration-v2.md   - Configuration reference"
echo -e "  • config.yaml.example        - Example configurations"
echo ""
